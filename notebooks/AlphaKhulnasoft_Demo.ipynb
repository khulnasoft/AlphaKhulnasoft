{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ AlphaKhulnasoft: Competitive AI Code Repair\n",
    "\n",
    "Welcome to the **AlphaKhulnasoft** demo! This notebook allows you to run the full flow-engineered code repair pipeline in Google Colab.\n",
    "\n",
    "### üí° What is AlphaKhulnasoft?\n",
    "It is a \"System 2\" agentic framework that doesn't just generate code once. It **Analyze ‚Üí Generates ‚Üí Tests ‚Üí Debugs ‚Üí Repairs** until it passes or hits a limit.\n",
    "\n",
    "**Note:** To run this demo, you will need an OpenAI, Anthropic, or Google Cloud (Vertex AI) API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Step 1: Environment Setup\n",
    "\n",
    "First, we install `uv` and setup our project environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Clone the repository (if not already present)\n",
    "if not os.path.exists(\"AlphaKhulnasoft\"):\n",
    "    !git clone https://github.com/KhulnaSoft/AlphaKhulnasoft.git\n",
    "\n",
    "%cd AlphaKhulnasoft\n",
    "\n",
    "# Install dependencies\n",
    "!uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Step 2: Configure Authentication\n",
    "\n",
    "Choose your provider below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: OpenAI / Anthropic / Hugging Face\n",
    "Set your API keys manually or use Colab Secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# OpenAI\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    val = getpass.getpass(\"Enter your OpenAI API Key (leave empty to skip): \")\n",
    "    if val:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = val\n",
    "\n",
    "# Anthropic\n",
    "if \"ANTHROPIC_API_KEY\" not in os.environ:\n",
    "    val = getpass.getpass(\"Enter your Anthropic API Key (leave empty to skip): \")\n",
    "    if val:\n",
    "        os.environ[\"ANTHROPIC_API_KEY\"] = val\n",
    "\n",
    "# Hugging Face\n",
    "if \"HF_TOKEN\" not in os.environ:\n",
    "    val = getpass.getpass(\"Enter your Hugging Face Token (leave empty to skip): \")\n",
    "    if val:\n",
    "        os.environ[\"HF_TOKEN\"] = val\n",
    "\n",
    "print(\"‚úÖ Manual keys configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Google Cloud Vertex AI\n",
    "Run the cell below to authenticate with your Google Account and set your Project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()\n",
    "\n",
    "PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "os.environ[\"VERTEX_PROJECT\"] = PROJECT_ID\n",
    "os.environ[\"VERTEX_LOCATION\"] = LOCATION\n",
    "\n",
    "print(f\"‚úÖ Vertex AI configured for project: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåã Step 3: Load or Generate Problems\n",
    "\n",
    "You can either bootstrap a \"Golden Dataset\" with an LLM or fetch a benchmark directly from **Hugging Face Hub**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice A: Generate with LLM\n",
    "!uv run python -m alphakhulnasoft.dataset_gen --count 3\n",
    "\n",
    "# Choice B: Fetch from Hugging Face (e.g., HumanEval)\n",
    "import json\n",
    "from alphakhulnasoft.data_loader import DataLoader\n",
    "\n",
    "loader = DataLoader()\n",
    "hf_problems = loader.load_from_hf(\"openai/humaneval\", split=\"test\")\n",
    "print(f\"üì• Loaded {len(hf_problems)} problems from Hugging Face.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öîÔ∏è Step 4: Run the Gauntlet (The Benchmark)\n",
    "\n",
    "Now we run the **AlphaRepairAgent** against the target problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run python -m alphakhulnasoft.benchmark data/hard_mode.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 5: Visualize and Publish\n",
    "\n",
    "Finally, we generate charts and optionally publish results to the **Hugging Face Hub**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import IPython\n",
    "from alphakhulnasoft.publisher import HFPublisher\n",
    "\n",
    "# Find the latest results file\n",
    "results_files = glob.glob(\"results_*.json\")\n",
    "if results_files:\n",
    "    latest_results = max(results_files)\n",
    "    !uv run python -m alphakhulnasoft.visualizer {latest_results}\n",
    "\n",
    "    # Display graphs\n",
    "    print(\"\\n--- üìà Repair Trajectory ---\")\n",
    "    IPython.display.display(IPython.display.Image(\"repair_curve.png\"))\n",
    "\n",
    "    # Optional: Publish to Hugging Face\n",
    "    # repo_id = \"your-username/your-repo-name\"\n",
    "    # if os.environ.get(\"HF_TOKEN\"):\n",
    "    #     publisher = HFPublisher(repo_id)\n",
    "    #     publisher.publish_results(latest_results)\n",
    "else:\n",
    "    print(\"‚ùå No results found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}